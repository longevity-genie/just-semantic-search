services:
  meilisearch:
    image: docker.io/getmeili/meilisearch:v1.13.0 # we have to use it because migration got easier
    environment:
      - http_proxy
      - https_proxy
      - MEILI_MASTER_KEY=fancy_master_key
      - MEILI_NO_ANALYTICS=true
      - MEILI_ENV=development
      - MEILI_LOG_LEVEL=debug
      - MEILI_DB_PATH=/data.ms
      - MEILI_EXPERIMENTAL_ENABLE_METRICS=true
      - MEILI_EXPERIMENTAL_ENABLE_VECTORS=true
    ports:
      - 7700:7700
    cap_add: # needed to work smoothly on rootless Ubuntu 24.04
      - DAC_OVERRIDE # feel free to remove it if you are not using Ubuntu 24.04
    volumes:
      - ./meilisearch_data:/data.ms
    restart: unless-stopped
  rag-server:
    image: ghcr.io/longevity-genie/just-semantic-search/rag-server:latest
    # For Podman GPU support
    #devices:
    #  - nvidia.com/gpu=all
    # For Docker GPU support
    #deploy:
    #  resources:
    #    reservations:
    #      devices:
    #        - driver: nvidia
    #          count: all
    #          capabilities: [gpu]
    working_dir: /app
    depends_on:
      - meilisearch
    ports:
      - 8090:8090
    healthcheck:
      test: ["CMD-SHELL", "curl -s 0.0.0.0:8089 | grep -q REST && test -f ./env/.env.local"]
      interval: 15s
      retries: 10
      start_period: 15s
      timeout: 1s
    env_file:
      - .env
    environment:
      - APP_PORT=8090
      - APP_HOST=0.0.0.0 #app host inside container, 0's to expose
      - AGENT_PARENT_SECTION=agent_profiles
      - AGENT_DEBUG=false
      - AGENT_CONFIG_PATH=/app/chat_agent_profiles.yaml
      - USER_ID=${USER_ID:-${UID}}
      - GROUP_ID=${GROUP_ID:-${GID}}
      - EMBEDDING_MODEL=jinaai/jina-embeddings-v3
      - MEILI_MASTER_KEY=fancy_master_key
      - MEILISEARCH_HOST=127.0.0.1
      - MEILISEARCH_PORT=7700
    restart: on-failure:3
    volumes:
      - "./data:/data"
      - "./env:/app/env"
      - "./logs:/app/logs"
      - "./chat_agent_profiles.yaml:/app/chat_agent_profiles.yaml"
